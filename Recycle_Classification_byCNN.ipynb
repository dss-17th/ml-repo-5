{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Recycle_Classification_byCNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_QX0h_vmZLG"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqv5I4u8oMdf"
      },
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm.notebook import tqdm\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.transform import resize\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.image as mpimg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8x9UxRZjmakm"
      },
      "source": [
        "# load files\n",
        "with open('/content/drive/MyDrive/deeplearning_file/sg/imageswithoutcut.pickle', 'rb') as f:\n",
        "    images = pickle.load(f)\n",
        "\n",
        "with open('/content/drive/MyDrive/deeplearning_file/sg/labelswithoutcut.pickle', 'rb') as f:\n",
        "    labels = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcEr47g8mbRV"
      },
      "source": [
        "# 카테고리별 경로로 이미지 파일 불러오기\n",
        "canpath = '/content/drive/MyDrive/deeplearning_file/recyclable_materials/labeling_Img_1/can/cut/'\n",
        "glasspath = '/content/drive/MyDrive/deeplearning_file/recyclable_materials/labeling_Img_1/glass/cut/'\n",
        "paperpath = '/content/drive/MyDrive/deeplearning_file/recyclable_materials/labeling_Img_1/paper/cut/'\n",
        "plasticpath = '/content/drive/MyDrive/deeplearning_file/recyclable_materials/labeling_Img_1/plastic/cut/'\n",
        "canfiles = os.listdir(canpath)\n",
        "glassfiles = os.listdir(glasspath)\n",
        "paperfiles =  os.listdir(paperpath)\n",
        "plasticfiles = os.listdir(plasticpath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFQ0UXSHmlYj"
      },
      "source": [
        "folders = [canpath, glasspath,  paperpath,  plasticpath]\n",
        "files = [ canfiles,  glassfiles,  paperfiles,  plasticfiles]\n",
        "\n",
        "checks = set()\n",
        "for i in range(4) :\n",
        "    path = folders[i]\n",
        "    for file in files[i]:\n",
        "        image = mpimg.imread(path + file)\n",
        "        checks.add(image.shape[2])\n",
        "print(checks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqUiGKKgmrYA"
      },
      "source": [
        "checks = set()\n",
        "for i in range(4) :\n",
        "    path = folders[i]\n",
        "    for file in files[i]:\n",
        "        image = mpimg.imread(path + file)\n",
        "        if image.shape[2] == 4:\n",
        "            for _ in range(len(set(image[:,:,3].reshape(-1)))):\n",
        "                checks.add(set(image[:,:,3].reshape(-1)).pop())\n",
        "print(checks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-EkHnDlmvR2"
      },
      "source": [
        "# 이미지 리사이징 & array 변환 \n",
        "for i in range(4) :\n",
        "    path = folders[i]\n",
        "    bar_total = tqdm(files[i])\n",
        "\n",
        "    for file in bar_total:\n",
        "        image = mpimg.imread(path + file)\n",
        "        if image.shape[2] == 4:\n",
        "            image = image[:,:,:3]\n",
        "        images = np.append(images, np.array([resize(image, (128, 128, 3))]), axis=0)\n",
        "        if i == 0 :\n",
        "            labels.append('can')\n",
        "        elif i == 1 :\n",
        "            labels.append('glass')\n",
        "        elif i == 2 :\n",
        "            labels.append('paper')\n",
        "        elif i == 3 :\n",
        "            labels.append('plastic')\n",
        "        else:\n",
        "            print(f'{i}는 존재하지 않습니다.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jaALQuxmyj6"
      },
      "source": [
        "# 라벨인코딩\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(labels)\n",
        "labels_encoded = encoder.transform(labels)\n",
        "labels_encoded[:3], encoder.classes_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NQOF5OXm1ny"
      },
      "source": [
        "# 데이터셋 train, test 나누기\n",
        "X_train = np.concatenate((images[:int(s0*0.8)], images[s0:s0+int(s1*0.8)], images[s0+s1:s0+s1+int(s2*0.8)], images[s0+s1+s2:s0+s1+s2+int(s3 *0.8)], images[s0+s1+s2+s3:] ), axis=0)\n",
        "X_test = np.concatenate((images[int(s0*0.8):s0], images[s0+int(s1*0.8):s0+s1], images[s0+s1+int(s2*0.8):s0+s1+s2], images[s0+s1+s2+int(s3*0.8):s0+s1+s2+s3]), axis=0)\n",
        "y_train = np.concatenate((labels_encoded[:int(s0*0.8)], labels_encoded[s0:s0+int(s1*0.8)], labels_encoded[s0+s1:s0+s1+int(s2*0.8)], labels_encoded[s0+s1+s2:s0+s1+s2+int(s3 *0.8)], labels_encoded[s0+s1+s2+s3:]), axis=0)\n",
        "y_test = np.concatenate((labels_encoded[int(s0*0.8):s0], labels_encoded[s0+int(s1*0.8):s0+s1], labels_encoded[s0+s1+int(s2*0.8):s0+s1+s2], labels_encoded[s0+s1+s2+int(s3*0.8):s0+s1+s2+s3]), axis=0)\n",
        "\n",
        "X_train.shape, X_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzZ4lgYTm4zS"
      },
      "source": [
        "#### 모델 ####"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9uiNkBIm-KX"
      },
      "source": [
        "import time\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models, Input\n",
        "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\n",
        "from tensorflow.keras.layers import Dropout,Dense,Conv2D,MaxPooling2D,Flatten\n",
        "from functools import partial\n",
        "import  matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_naXmUCsYB9"
      },
      "source": [
        "# 바닐라 CNN\n",
        "\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(64, (5, 5), activation='relu', input_shape=(128,128,3)),\n",
        "    layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
        "    layers.Dropout(0.25),\n",
        "    \n",
        "    layers.Conv2D(128, (5, 5), activation='relu', padding='same'),\n",
        "    layers.MaxPool2D(pool_size=(2,2)),\n",
        "    layers.Dropout(0.25),\n",
        "    \n",
        "    layers.Conv2D(128, (5, 5), activation='relu', padding='same'),\n",
        "    layers.MaxPool2D(pool_size=(2,2)),\n",
        "    layers.Dropout(0.25),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dropout(0.25),\n",
        "    layers.Dense(4, activation='softmax')\n",
        "    \n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIGA1G-9sauy"
      },
      "source": [
        "# resnet 50\n",
        "\n",
        "\n",
        "# # The identity block\n",
        "# def identity_block(X, f, filters, stage, block):\n",
        "#   conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "#   bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "#   F1, F2, F3 = filters\n",
        "#   X_shortcut = X\n",
        "#   # first step of main path\n",
        "#   X = tf.keras.layers.Conv2D(filters=F1, kernel_size=1, strides=1, padding='valid', name=conv_name_base + '2a',\n",
        "#   kernel_initializer=tf.keras.initializers.glorot_uniform(seed=0))(X)\n",
        "#   X = tf.keras.layers.BatchNormalization(axis=3, name=bn_name_base+'2a')(X)\n",
        "#   X = tf.keras.layers.Activation('relu')(X)\n",
        "#   # second step of main path\n",
        "#   X = tf.keras.layers.Conv2D(filters=F2, kernel_size=f, strides=1, padding='same', name=conv_name_base + '2b',\n",
        "#   kernel_initializer=tf.keras.initializers.glorot_uniform(seed=0))(X)\n",
        "#   X = tf.keras.layers.BatchNormalization(axis=3, name=bn_name_base+'2b')(X)\n",
        "#   X = tf.keras.layers.Activation('relu')(X)\n",
        "#   # third step of main path\n",
        "#   X = tf.keras.layers.Conv2D(filters=F3, kernel_size=1, strides=1, padding='valid', name=conv_name_base + '2c',\n",
        "#   kernel_initializer=tf.keras.initializers.glorot_uniform(seed=0))(X)\n",
        "#   X = tf.keras.layers.BatchNormalization(axis=3, name=bn_name_base+'2c')(X)\n",
        "#   # add shortcut value and pass it through a ReLU activation\n",
        "#   X = tf.keras.layers.Add()([X, X_shortcut])\n",
        "#   X = tf.keras.layers.Activation('relu')(X)\n",
        "#   return X\n",
        "\n",
        "# # Convolutional Block\n",
        "# def convolutional_block(X, f, filters, stage, block, s=2):\n",
        "#   conv_name_base = 'res'+str(stage)+block+'_branch'\n",
        "#   bn_name_base = 'bn'+str(stage)+block+'_branch'\n",
        "#   F1, F2, F3 = filters\n",
        "#   X_shortcut = X\n",
        "#   # first step of main path\n",
        "#   X = tf.keras.layers.Conv2D(filters=F1, kernel_size=1, strides=s, padding='valid', name=conv_name_base+'2a',\n",
        "#   kernel_initializer=tf.keras.initializers.glorot_uniform(seed=0))(X)\n",
        "#   X = tf.keras.layers.BatchNormalization(axis=3, name=bn_name_base+'2a')(X)\n",
        "#   X = tf.keras.layers.Activation('relu')(X)\n",
        "#   # second step of main path\n",
        "#   X = tf.keras.layers.Conv2D(filters=F2, kernel_size=f, strides=1, padding='same', name=conv_name_base+'2b',\n",
        "#   kernel_initializer=tf.keras.initializers.glorot_uniform(seed=0))(X)\n",
        "#   X = tf.keras.layers.BatchNormalization(axis=3, name=bn_name_base+'2b')(X)\n",
        "#   X = tf.keras.layers.Activation('relu')(X)\n",
        "#   # third step of main path\n",
        "#   X = tf.keras.layers.Conv2D(filters=F3, kernel_size=1, strides=1, padding='valid', name=conv_name_base+'2c',\n",
        "#   kernel_initializer=tf.keras.initializers.glorot_uniform(seed=0))(X)\n",
        "#   X = tf.keras.layers.BatchNormalization(axis=3, name=bn_name_base+'2c')(X)\n",
        "#   # shortcut path\n",
        "#   X_shortcut = tf.keras.layers.Conv2D(filters=F3, kernel_size=1, strides=s, padding='valid', name=conv_name_base+'1',\n",
        "#   kernel_initializer=tf.keras.initializers.glorot_uniform(seed=0))(X_shortcut)\n",
        "#   X_shortcut = tf.keras.layers.BatchNormalization(axis=3, name=bn_name_base+'1')(X_shortcut)\n",
        "#   # Add and pass it through a ReLU activation\n",
        "#   X = tf.keras.layers.Add()([X, X_shortcut])\n",
        "#   X = tf.keras.layers.Activation('relu')(X)\n",
        "#   return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omC_Ws-hKDjc"
      },
      "source": [
        "# def ResNet50(input_shape=(128,128,3), classes=4):\n",
        "#   X_input = tf.keras.layers.Input(input_shape)\n",
        "#   # zero padding\n",
        "#   X = tf.keras.layers.ZeroPadding2D((3,3))(X_input)\n",
        "#   # stage 1\n",
        "#   X = tf.keras.layers.Conv2D(filters=64, kernel_size=7, strides=2, name='conv1',\n",
        "#   kernel_initializer=tf.keras.initializers.glorot_uniform(seed=0))(X)\n",
        "#   X = tf.keras.layers.BatchNormalization(axis=3, name='bn_conv1')(X)\n",
        "#   X = tf.keras.layers.Activation('relu')(X)\n",
        "#   X = tf.keras.layers.MaxPooling2D((3,3), strides=(2,2))(X)\n",
        "#   # stage 2\n",
        "#   X = convolutional_block(X, f=3, filters=[64,64,256], stage=2, block='a', s=1)\n",
        "#   X = identity_block(X, 3, [64,64,256], stage=2, block='b')\n",
        "#   X = identity_block(X, 3, [64,64,256], stage=2, block='c')\n",
        "#   # stage 3\n",
        "#   X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
        "#   X = identity_block(X, 3, [128, 128, 512], stage = 3, block='b')\n",
        "#   X = identity_block(X, 3, [128, 128, 512], stage = 3, block='c')\n",
        "#   X = identity_block(X, 3, [128, 128, 512], stage = 3, block='d')\n",
        "#   # Stage 4\n",
        "#   X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
        "#   X = identity_block(X, 3, [256, 256, 1024], stage = 4, block='b')\n",
        "#   X = identity_block(X, 3, [256, 256, 1024], stage = 4, block='c')\n",
        "#   X = identity_block(X, 3, [256, 256, 1024], stage = 4, block='d')\n",
        "#   X = identity_block(X, 3, [256, 256, 1024], stage = 4, block='e')\n",
        "#   X = identity_block(X, 3, [256, 256, 1024], stage = 4, block='f')\n",
        "#   # Stage 5\n",
        "#   X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
        "#   X = identity_block(X, 3, [512, 512, 2048], stage = 5, block='b')\n",
        "#   X = identity_block(X, 3, [512, 512, 2048], stage = 5, block='c')\n",
        "#   # AVGPOOL\n",
        "#   X = tf.keras.layers.AveragePooling2D()(X)\n",
        "#   # output layer\n",
        "#   X = tf.keras.layers.Flatten()(X)\n",
        "#   X = tf.keras.layers.Dense(classes, activation='softmax', name='fc'+str(classes),\n",
        "#   kernel_initializer=tf.keras.initializers.glorot_uniform(seed=0))(X)\n",
        "#   # Create Model\n",
        "#   model = tf.keras.models.Model(inputs=X_input, outputs=X, name='ResNet50')\n",
        "#   return model\n",
        "\n",
        "# from keras import optimizers\n",
        "# from tensorflow import keras\n",
        "\n",
        "# model = ResNet50(input_shape = (128, 128, 3), classes = 4)\n",
        "# adam = optimizers.Adam(learning_rate=0.001)\n",
        "# model.compile(optimizer=adam,\n",
        "#              loss='sparse_categorical_crossentropy',\n",
        "#              metrics=['accuracy'])\n",
        "# model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ok_oioBdsa8i"
      },
      "source": [
        "# vgg16\n",
        "\n",
        "\n",
        "# def VGG16_model():\n",
        "#   tf.random.set_seed(2)\n",
        "#   model = tf.keras.models.Sequential([\n",
        "#   # Conv 1\n",
        "#   layers.Conv2D(64, (3, 3), strides=1, padding='same', activation='relu',\n",
        "#   input_shape=(128,128,3), name='conv1_1'),\n",
        "#   layers.Conv2D(64, (3, 3), strides=1, padding='same', activation='relu', name='conv1_2'),\n",
        "#   layers.MaxPool2D((2,2), padding='same', name='conv1_MaxPool'),\n",
        "#   # Conv 2\n",
        "#   layers.Conv2D(128, (3, 3), strides=1, padding='same', activation='relu', name='conv2_1'),\n",
        "#   layers.Conv2D(128, (3, 3), strides=1, padding='same', activation='relu', name='conv2_2'),\n",
        "#   layers.MaxPool2D((2,2), padding='same', name='conv2_MaxPool'),\n",
        "#   # Conv3\n",
        "#   layers.Conv2D(256, (3, 3), strides=1, padding='same', activation='relu', name='conv3_1'),\n",
        "#   layers.Conv2D(256, (3, 3), strides=1, padding='same', activation='relu', name='conv3_2'),\n",
        "#   layers.Conv2D(256, (3, 3), strides=1, padding='same', activation='relu', name='conv3_3'),\n",
        "#   layers.MaxPool2D((2,2), padding='same', name='conv3_MaxPool'),\n",
        "#   # Conv4\n",
        "#   layers.Conv2D(512, (3, 3), strides=1, padding='same', activation='relu', name='conv4_1'),\n",
        "#   layers.Conv2D(512, (3, 3), strides=1, padding='same', activation='relu', name='conv4_2'),\n",
        "#   layers.Conv2D(512, (3, 3), strides=1, padding='same', activation='relu', name='conv4_3'),\n",
        "#   layers.MaxPool2D((2,2), padding='same', name='conv4_MaxPool'),\n",
        "#   # Conv5\n",
        "#   layers.Conv2D(512, (3, 3), strides=1, padding='same', activation='relu', name='conv5_1'),\n",
        "#   layers.Conv2D(512, (3, 3), strides=1, padding='same', activation='relu', name='conv5_2'),\n",
        "#   layers.Conv2D(512, (3, 3), strides=1, padding='same', activation='relu', name='conv5_3'),\n",
        "#   layers.MaxPool2D((2,2), padding='same', name='conv5_MaxPool'),\n",
        "#   # Flatten\n",
        "#   layers.Flatten(),\n",
        "#   # Dropout\n",
        "#   layers.Dropout(0.5),\n",
        "#   # FC1\n",
        "#   layers.Dense(512, activation='relu'),\n",
        "#   # output\n",
        "#   layers.Dense(4, activation='softmax'),\n",
        "#   ])\n",
        "\n",
        "#   return model\n",
        "# model = VGG16_model()\n",
        "# model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXzLGawEsdGZ"
      },
      "source": [
        "# google-net\n",
        "\n",
        "# def inception(x,\n",
        "#               filters_1x1,\n",
        "#               filters_3x3_reduce,\n",
        "#               filters_3x3,\n",
        "#               filters_5x5_reduce,\n",
        "#               filters_5x5,\n",
        "#               filters_pool):\n",
        "#   path1 = layers.Conv2D(filters_1x1, (1, 1), padding='same', activation='relu')(x)\n",
        "\n",
        "#   path2 = layers.Conv2D(filters_3x3_reduce, (1, 1), padding='same', activation='relu')(x)\n",
        "#   path2 = layers.Conv2D(filters_3x3, (1, 1), padding='same', activation='relu')(path2)\n",
        "\n",
        "#   path3 = layers.Conv2D(filters_5x5_reduce, (1, 1), padding='same', activation='relu')(x)\n",
        "#   path3 = layers.Conv2D(filters_5x5, (1, 1), padding='same', activation='relu')(path3)\n",
        "\n",
        "#   path4 = layers.MaxPool2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "#   path4 = layers.Conv2D(filters_pool, (1, 1), padding='same', activation='relu')(path4)\n",
        "\n",
        "#   return tf.concat([path1, path2, path3, path4], axis=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBnew0Xqsj06"
      },
      "source": [
        "# inp = layers.Input(shape=(128, 128, 3))\n",
        "# input_tensor = layers.experimental.preprocessing.Resizing(224, 224, interpolation=\"bilinear\", input_shape=X_train.shape[1:])(inp)\n",
        "\n",
        "# x = layers.Conv2D(64, 7, strides=2, padding='same', activation='relu')(input_tensor)\n",
        "# x = layers.MaxPooling2D(3, strides=2)(x)\n",
        "\n",
        "# x = layers.Conv2D(64, 1, strides=1, padding='same', activation='relu')(x)\n",
        "# x = layers.Conv2D(192, 3, strides=1, padding='same', activation='relu')(x)\n",
        "\n",
        "# x = layers.MaxPooling2D(3, strides=2)(x)\n",
        "\n",
        "# x = inception(x,\n",
        "#               filters_1x1=64,\n",
        "#               filters_3x3_reduce=96,\n",
        "#               filters_3x3=128,\n",
        "#               filters_5x5_reduce=16,\n",
        "#               filters_5x5=32,\n",
        "#               filters_pool=32)\n",
        "\n",
        "# x = inception(x,\n",
        "#               filters_1x1=128,\n",
        "#               filters_3x3_reduce=128,\n",
        "#               filters_3x3=192,\n",
        "#               filters_5x5_reduce=32,\n",
        "#               filters_5x5=96,\n",
        "#               filters_pool=64)\n",
        "\n",
        "# x = layers.MaxPooling2D(3, strides=2)(x)\n",
        "\n",
        "# x = inception(x,\n",
        "#               filters_1x1=192,\n",
        "#               filters_3x3_reduce=96,\n",
        "#               filters_3x3=208,\n",
        "#               filters_5x5_reduce=16,\n",
        "#               filters_5x5=48,\n",
        "#               filters_pool=64)\n",
        "\n",
        "# aux1 = layers.AveragePooling2D((5, 5), strides=3)(x)\n",
        "# aux1 = layers.Conv2D(128, 1, padding='same', activation='relu')(aux1)\n",
        "# aux1 = layers.Flatten()(aux1)\n",
        "# aux1 = layers.Dense(1024, activation='relu')(aux1)\n",
        "# aux1 = layers.Dropout(0.7)(aux1)\n",
        "# aux1 = layers.Dense(4, activation='softmax')(aux1)\n",
        "\n",
        "# x = inception(x,\n",
        "#               filters_1x1=160,\n",
        "#               filters_3x3_reduce=112,\n",
        "#               filters_3x3=224,\n",
        "#               filters_5x5_reduce=24,\n",
        "#               filters_5x5=64,\n",
        "#               filters_pool=64)\n",
        "\n",
        "# x = inception(x,\n",
        "#               filters_1x1=128,\n",
        "#               filters_3x3_reduce=128,\n",
        "#               filters_3x3=256,\n",
        "#               filters_5x5_reduce=24,\n",
        "#               filters_5x5=64,\n",
        "#               filters_pool=64)\n",
        "\n",
        "# x = inception(x,\n",
        "#               filters_1x1=112,\n",
        "#               filters_3x3_reduce=144,\n",
        "#               filters_3x3=288,\n",
        "#               filters_5x5_reduce=32,\n",
        "#               filters_5x5=64,\n",
        "#               filters_pool=64)\n",
        "\n",
        "# aux2 = layers.AveragePooling2D((5, 5), strides=3)(x)\n",
        "# aux2 = layers.Conv2D(128, 1, padding='same', activation='relu')(aux2)\n",
        "# aux2 = layers.Flatten()(aux2)\n",
        "# aux2 = layers.Dense(1024, activation='relu')(aux2)\n",
        "# aux2 = layers.Dropout(0.7)(aux2)\n",
        "# aux2 = layers.Dense(4, activation='softmax')(aux2)\n",
        "\n",
        "# x = inception(x,\n",
        "#               filters_1x1=256,\n",
        "#               filters_3x3_reduce=160,\n",
        "#               filters_3x3=320,\n",
        "#               filters_5x5_reduce=32,\n",
        "#               filters_5x5=128,\n",
        "#               filters_pool=128)\n",
        "\n",
        "# x = layers.MaxPooling2D(3, strides=2)(x)\n",
        "\n",
        "# x = inception(x,\n",
        "#               filters_1x1=256,\n",
        "#               filters_3x3_reduce=160,\n",
        "#               filters_3x3=320,\n",
        "#               filters_5x5_reduce=32,\n",
        "#               filters_5x5=128,\n",
        "#               filters_pool=128)\n",
        "\n",
        "# x = inception(x,\n",
        "#               filters_1x1=384,\n",
        "#               filters_3x3_reduce=192,\n",
        "#               filters_3x3=384,\n",
        "#               filters_5x5_reduce=48,\n",
        "#               filters_5x5=128,\n",
        "#               filters_pool=128)\n",
        "\n",
        "# x = layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "# x = layers.Dropout(0.4)(x)\n",
        "# out = layers.Dense(4, activation='softmax')(x)\n",
        "\n",
        "# model = tf.keras.models.Model(inputs = inp, outputs = [out, aux1, aux2])\n",
        "# early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.001, patience=10, verbose=1, mode='min', baseline=None, restore_best_weights=False)\n",
        "# mc = keras.callbacks.ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True)\n",
        "# model.compile(optimizer='adam', \n",
        "#               loss=['sparse_categorical_crossentropy','sparse_categorical_crossentropy','sparse_categorical_crossentropy'], \n",
        "#               loss_weights=[1, 0.3, 0.3], metrics=['accuracy'], \n",
        "#               )\n",
        "# model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_vtpppbtD1V"
      },
      "source": [
        "# 모델 구성\n",
        "model.compile(optimizer='adam',\n",
        "             loss='sparse_categorical_crossentropy',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWq8A-4ftHWG"
      },
      "source": [
        "# 모델 훈련시키기\n",
        "\n",
        "callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                           patience=5),\n",
        "             keras.callbacks.ModelCheckpoint(filepath='best_model.h5',\n",
        "                                             monitor='val_loss',\n",
        "                                             save_best_only=True)]\n",
        "hist = model.fit(X_train, y_train,\n",
        "                batch_size=32,\n",
        "                epochs=100,\n",
        "                validation_data = (X_test, y_test),\n",
        "               callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NZ_XwhStIto"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYl4X81FF1Gu"
      },
      "source": [
        "# imagenet 사전학습 모델\n",
        "# X-ception\n",
        "\n",
        "# tf.keras.backend.clear_session()\n",
        "# tf.random.set_seed(42)\n",
        "# np.random.seed(42)\n",
        "\n",
        "# xception_model = keras.applications.xception.Xception(weights=\"imagenet\",\n",
        "#                                                       include_top=False,\n",
        "#                                                       input_shape = (128,128,3))\n",
        "# avg = keras.layers.GlobalAveragePooling2D()(xception_model.output)\n",
        "# output = keras.layers.Dense(4, activation=\"softmax\")(avg)\n",
        "# model = keras.models.Model(inputs=xception_model.input, outputs=output)\n",
        "\n",
        "# optimizer = keras.optimizers.Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
        "# model.compile(optimizer =optimizer ,loss = 'sparse_categorical_crossentropy',metrics =['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pM0m-1fiF1wX"
      },
      "source": [
        "# early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience = 10,restore_best_weights = True)\n",
        "# lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(factor = 0.7,patience = 2)\n",
        "# model_checkpoint =tf.keras.callbacks.ModelCheckpoint('GarbageClassifier_Xce.h5', save_best_only=True)\n",
        "\n",
        "# class CustomCallBack(tf.keras.callbacks.Callback):\n",
        "#         def on_epoch_end(self,epoch,logs={}):\n",
        "#             if(logs.get('val_loss')<0.5):\n",
        "#                 print(\"\\n cancelling training!\")\n",
        "#                 self.model.stop_training = True\n",
        "                \n",
        "# mycallback = CustomCallBack()\n",
        "\n",
        "# hist = model.fit(\n",
        "#     X_train, y_train, batch_size=32,\n",
        "#     epochs = 1000,\n",
        "#     validation_data = (X_test, y_test),\n",
        "#     callbacks= [early_stopping_cb,model_checkpoint,lr_scheduler,mycallback],\n",
        "#     verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttHZsviJ88EO"
      },
      "source": [
        "# # inception-v3\n",
        "\n",
        "# tf.keras.backend.clear_session()\n",
        "# tf.random.set_seed(42)\n",
        "# np.random.seed(42)\n",
        "\n",
        "# inception_model = keras.applications.InceptionV3(weights=\"imagenet\",\n",
        "#                                                       include_top=False,\n",
        "#                                                       input_shape = (128,128,3))\n",
        "# avg = keras.layers.GlobalAveragePooling2D()(inception_model.output)\n",
        "# output = keras.layers.Dense(4, activation=\"softmax\")(avg)\n",
        "# model = keras.models.Model(inputs=inception_model.input, outputs=output)\n",
        "\n",
        "# optimizer = keras.optimizers.Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
        "# model.compile(optimizer =optimizer ,loss = 'sparse_categorical_crossentropy',metrics =['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cmjcsHB88YH"
      },
      "source": [
        "# epochs = 50                \n",
        "\n",
        "\n",
        "# hist = model.fit(\n",
        "#     X_train, y_train, batch_size=32,\n",
        "#     epochs = epochs,\n",
        "#     validation_data = (X_test, y_test),\n",
        "#     verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbqF4RwbSXUu"
      },
      "source": [
        "# history = pd.DataFrame([range(1, epochs+1), hist.history['val_loss'], hist.history['val_accuracy'],['Inception-v3' for _ in range(epochs) ]]).T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sT5yy6NOSXpw"
      },
      "source": [
        "# history.columns = ['epochs', 'loss', 'accuracy', 'model', ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W12MyUdTSX7L"
      },
      "source": [
        "# # top_score = val_loss=0.385, val_acc=0.881\n",
        "# history.sort_values('loss',ascending=True) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcmKlQVISeID"
      },
      "source": [
        "# # Efficient-net\n",
        "\n",
        "# from keras.layers import Dense\n",
        "# from keras.optimizers import Adam\n",
        "\n",
        "# efficient_net = EfficientNetB7(\n",
        "#     weights='imagenet',\n",
        "#     input_shape=(128,128,3),\n",
        "#     include_top=False,\n",
        "#     pooling='max'\n",
        "# )\n",
        "\n",
        "# model = Sequential()\n",
        "# model.add(efficient_net)\n",
        "# model.add(Dense(units = 120, activation='relu'))\n",
        "# model.add(Dense(units = 120, activation = 'relu'))\n",
        "# model.add(Dense(units = 1, activation='softmax'))\n",
        "# model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdNm4fgHSsM2"
      },
      "source": [
        "# model.compile(optimizer=Adam(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# epochs = 50                \n",
        "\n",
        "\n",
        "# hist = model.fit(\n",
        "#     X_train, y_train, batch_size=32,\n",
        "#     epochs = epochs,\n",
        "#     steps_per_epoch = 15,\n",
        "#     validation_data = (X_test, y_test),\n",
        "#     validation_steps = 7,\n",
        "#     verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2ByaibStJBz"
      },
      "source": [
        "# 모델 평가 확인\n",
        "test_loss, test_acc = model.evaluate(X_test,y_test)\n",
        "print('test loss:', test_loss, 'test_accuracy:',test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuxMptIztgbK"
      },
      "source": [
        "# 그래프\n",
        "\n",
        "plot_target = ['loss', 'val_loss', 'accuracy', 'val_accuracy']\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "for each in plot_target:\n",
        "    plt.plot(hist.history[each], label=each)\n",
        "\n",
        "plt.legend()\n",
        "plt.ylim(0,1)\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgJ6X1CLth4i"
      },
      "source": [
        "# 그래프2\n",
        "fig, axs = plt.subplots(2,1, figsize=(6,10))\n",
        "\n",
        "axs[0].plot(hist.history['loss'])\n",
        "axs[0].plot(hist.history['val_loss'])\n",
        "axs[0].title.set_text('Loss vs Val_Loss')\n",
        "axs[0].set_xlabel('Epochs')\n",
        "axs[0].set_ylabel('Loss')\n",
        "axs[0].legend(['Train','Val'])\n",
        "\n",
        "axs[1].plot(hist.history['dense_4_accuracy'])\n",
        "axs[1].plot(hist.history['val_dense_4_accuracy'])\n",
        "axs[1].title.set_text('Accuracy vs Val_Accuracy')\n",
        "axs[1].set_xlabel('Epochs')\n",
        "axs[1].set_ylabel('Accuracy')\n",
        "axs[1].legend(['Train', 'Val'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bz7xi_MutrFc"
      },
      "source": [
        "# Confusion Matrix\n",
        "predicted_result = model.predict(X_test)\n",
        "predicted_labels = np.argmax(predicted_result, axis=1)\n",
        "commands = ['can',  'glass', 'paper', 'plastic']\n",
        "\n",
        "confusion_mtx = tf.math.confusion_matrix(y_test, predicted_labels)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(confusion_mtx, xticklabels=commands, yticklabels=commands, annot=True, fmt='g')\n",
        "plt.xlabel('Prediction')\n",
        "plt.ylabel('Label')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}